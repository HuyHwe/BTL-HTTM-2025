{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72174e76",
   "metadata": {},
   "source": [
    "## Bước 1: Tạo X, y là bộ dữ liệu từ ảnh png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a0bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a dummy image at: test_image.png\n",
      "\n",
      "Successfully converted image to TensorFlow tensor!\n",
      "Tensor shape: (1, 100, 100, 3)\n",
      "Data type: <dtype: 'float32'>\n",
      "\n",
      "Cleaned up dummy file: test_image.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 07:06:52.019829: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-09-16 07:06:52.019840: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-16 07:06:52.019846: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-09-16 07:06:52.020272: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-16 07:06:52.020660: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2712, 144, 192, 3) (2712,)\n"
     ]
    }
   ],
   "source": [
    "# Merge all the code into a single script\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def parse_png_to_tensor(image_path: str) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Parses a PNG image file into a TensorFlow tensor.\n",
    "\n",
    "    This function is updated to be compatible with a TensorFlow training loop.\n",
    "    It converts the image to RGB format, normalizes the pixel values to a\n",
    "    0-1 range, and adds a batch dimension.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the PNG image.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A TensorFlow tensor of the image with a shape of\n",
    "                   (1, height, width, 3). Returns an empty tensor if the file\n",
    "                   cannot be processed.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File not found at {image_path}\")\n",
    "        return tf.empty(0)\n",
    "\n",
    "    try:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert the image to RGB format. This handles different modes like RGBA or P.\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert the PIL Image object to a NumPy array.\n",
    "        # The shape of the array will be (height, width, channels)\n",
    "        numpy_array = np.array(image, dtype=np.float32)\n",
    "        \n",
    "        # Normalize the pixel values from 0-255 to 0.0-1.0\n",
    "        normalized_array = numpy_array / 255.0\n",
    "        \n",
    "        # Convert the NumPy array to a TensorFlow tensor.\n",
    "        # The tensor will have a shape of (height, width, channels)\n",
    "        image_tensor = tf.convert_to_tensor(normalized_array)\n",
    "        \n",
    "        # Add a batch dimension at the beginning to match the expected\n",
    "        # input shape for a model (batch_size, height, width, channels)\n",
    "        final_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "        return final_tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the image: {e}\")\n",
    "        return tf.empty(0)\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a dummy PNG file for testing\n",
    "    dummy_image_path = \"test_image.png\"\n",
    "    \n",
    "    # Create a 100x100 white image with RGB channels\n",
    "    dummy_image = Image.new('RGB', (100, 100), 'white')\n",
    "    dummy_image.save(dummy_image_path)\n",
    "    print(f\"Created a dummy image at: {dummy_image_path}\")\n",
    "\n",
    "    # Call the parse function on the dummy image\n",
    "    image_tensor = parse_png_to_tensor(dummy_image_path)\n",
    "\n",
    "    # Check the result\n",
    "    if image_tensor.shape.num_elements() > 0:\n",
    "        print(\"\\nSuccessfully converted image to TensorFlow tensor!\")\n",
    "        print(f\"Tensor shape: {image_tensor.shape}\")\n",
    "        print(f\"Data type: {image_tensor.dtype}\")\n",
    "    else:\n",
    "        print(\"\\nFailed to convert image to tensor.\")\n",
    "\n",
    "    # Clean up the dummy file\n",
    "    os.remove(dummy_image_path)\n",
    "    print(f\"\\nCleaned up dummy file: {dummy_image_path}\")\n",
    "\n",
    "\n",
    "IMG_SIZE = [144, 192]\n",
    "labels = [l for l in os.listdir(\"./dataset\") if l != \".DS_Store\"]\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "for i, label in enumerate(labels):\n",
    "    img_list = os.listdir(f\"./dataset/{label}/\")\n",
    "    for img in img_list:\n",
    "        img_path = f\"./dataset/{label}/{img}\"\n",
    "        tensor = parse_png_to_tensor(img_path)\n",
    "        # Resize and check for valid tensor\n",
    "        if tensor.shape.num_elements() > 0:\n",
    "            resized = tf.image.resize(tf.squeeze(tensor, axis=0), IMG_SIZE)\n",
    "            X_list.append(resized)\n",
    "            y_list.append(i)\n",
    "\n",
    "X = tf.stack(X_list, axis=0)\n",
    "y = tf.convert_to_tensor(y_list, dtype=tf.int32)\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d7034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2712, 144, 192, 3]), TensorShape([2712]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e13c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = [144,192]\n",
    "NUM_CLASSES = 12\n",
    "BATCH = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# def parse_example(path, label):\n",
    "#     img = tf.io.read_file(path)\n",
    "#     img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "#     img = tf.image.resize(img, [IMG_SIZE[0], IMG_SIZE[1]], antialias=True)\n",
    "#     img = tf.cast(img, tf.float32) / 255.0\n",
    "#     return img, tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "# def augment(img, label):\n",
    "#     img = tf.image.random_flip_left_right(img)\n",
    "#     img = tf.image.random_brightness(img, max_delta=0.08)\n",
    "#     img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "#     img = tf.image.random_saturation(img, 0.9, 1.1)\n",
    "#     return img, label\n",
    "\n",
    "# def make_ds(paths, labels, training=True):\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "#     ds = ds.shuffle(2048) if training else ds\n",
    "#     ds = ds.map(parse_example, num_parallel_calls=AUTOTUNE)\n",
    "#     ds = ds.map(augment, num_parallel_calls=AUTOTUNE) if training else ds\n",
    "#     return ds.batch(BATCH).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32838d",
   "metadata": {},
   "source": [
    "## CNN without Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85c53a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_init(shape):\n",
    "    fan_in = tf.cast(tf.math.reduce_prod(shape[:-1]), tf.float32)\n",
    "    std = tf.sqrt(2.0/fan_in)\n",
    "    return tf.random.normal(shape, stddev=std)\n",
    "\n",
    "class SimpleCNN:\n",
    "    def __init__(self, num_classes=12):\n",
    "        self.W1 = tf.Variable(he_init([3,3,3,32]));  self.b1 = tf.Variable(tf.zeros([32]))\n",
    "        self.W2 = tf.Variable(he_init([3,3,32,64])); self.b2 = tf.Variable(tf.zeros([64]))\n",
    "        self.W3 = tf.Variable(he_init([3,3,64,128]));self.b3 = tf.Variable(tf.zeros([128]))\n",
    "        \n",
    "        # We will initialize the weights for the dense layers dynamically\n",
    "        # based on the input image shape.\n",
    "        self.W4 = None\n",
    "        self.b4 = None\n",
    "        self.W5 = tf.Variable(he_init([256, num_classes]))\n",
    "        self.b5 = tf.Variable(tf.zeros([num_classes]))\n",
    "        self.weights_initialized = False\n",
    "\n",
    "    def __call__(self, x, training=False, drop_rate=0.3):\n",
    "        # x: [B, H, W, 3]\n",
    "        x = tf.nn.conv2d(x, self.W1, strides=1, padding='SAME') + self.b1\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        x = tf.nn.conv2d(x, self.W2, strides=1, padding='SAME') + self.b2\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        x = tf.nn.conv2d(x, self.W3, strides=1, padding='SAME') + self.b3\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        if not self.weights_initialized:\n",
    "            # Dynamically calculate the flattened dimension and initialize weights\n",
    "            # This is done the first time the model is called with a new input shape\n",
    "            flat_dim = tf.math.reduce_prod(x.shape[1:])\n",
    "            self.W4 = tf.Variable(he_init([flat_dim, 256]))\n",
    "            self.b4 = tf.Variable(tf.zeros([256]))\n",
    "            self.weights_initialized = True\n",
    "\n",
    "        x = tf.reshape(x, [-1, tf.math.reduce_prod(x.shape[1:])])\n",
    "        x = tf.matmul(x, self.W4) + self.b4\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        if training and drop_rate > 0:\n",
    "            keep = 1.0 - drop_rate\n",
    "            mask = tf.cast(tf.random.uniform(tf.shape(x)) < keep, x.dtype)\n",
    "            x = (x * mask) / keep\n",
    "\n",
    "        logits = tf.matmul(x, self.W5) + self.b5\n",
    "        return logits\n",
    "\n",
    "    @property\n",
    "    def variables(self):\n",
    "        # Make sure to return all variables, including the dynamically created ones\n",
    "        return [self.W1,self.b1,self.W2,self.b2,self.W3,self.b3,self.W4,self.b4,self.W5,self.b5]\n",
    "\n",
    "import math\n",
    "\n",
    "def cross_entropy_loss(logits, onehot_labels):\n",
    "    per_ex = tf.nn.softmax_cross_entropy_with_logits(labels=onehot_labels, logits=logits)\n",
    "    return tf.reduce_mean(per_ex)\n",
    "\n",
    "def accuracy(logits, onehot_labels):\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    true = tf.argmax(onehot_labels, axis=1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=1e-3, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}\n",
    "\n",
    "    def apply_gradients(self, grads, vars):\n",
    "        for g, v in zip(grads, vars):\n",
    "            if g is None:\n",
    "                continue\n",
    "            key = id(v)\n",
    "            if key not in self.v:\n",
    "                self.v[key] = tf.zeros_like(v)\n",
    "            self.v[key] = self.momentum*self.v[key] + g\n",
    "            v.assign_sub(self.lr * self.v[key])\n",
    "\n",
    "def train(model, ds_train, ds_val, epochs=15, lr=1e-3):\n",
    "    opt = SGD(lr=lr, momentum=0.9)\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss = tf.metrics.Mean(); tr_acc = tf.metrics.Mean()\n",
    "        for x,y in ds_train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x, training=True)\n",
    "                loss = cross_entropy_loss(logits, y)\n",
    "            grads = tape.gradient(loss, model.variables)\n",
    "            opt.apply_gradients(grads, model.variables)\n",
    "\n",
    "            tr_loss.update_state(loss)\n",
    "            tr_acc.update_state(accuracy(logits, y))\n",
    "\n",
    "        va_loss = tf.metrics.Mean(); va_acc = tf.metrics.Mean()\n",
    "        for x,y in ds_val:\n",
    "            logits = model(x, training=False)\n",
    "            va_loss.update_state(cross_entropy_loss(logits, y))\n",
    "            va_acc.update_state(accuracy(logits, y))\n",
    "\n",
    "        print(f\"Epoch {ep:02d} | train_loss={tr_loss.result():.4f} acc={tr_acc.result():.4f} \"\n",
    "              f\"| val_loss={va_loss.result():.4f} acc={va_acc.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8263ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating pre-existing X and y tensors...\n",
      "Loaded X shape: (2712, 144, 192, 3)\n",
      "Loaded y shape: (2712,)\n",
      "\n",
      "Starting CNN training...\n",
      "Epoch 01 | train_loss=2.3696 acc=0.1949 | val_loss=1.9582 acc=0.3999\n",
      "Epoch 02 | train_loss=1.6791 acc=0.4260 | val_loss=1.2268 acc=0.6279\n",
      "Epoch 03 | train_loss=1.0446 acc=0.6425 | val_loss=0.8838 acc=0.7027\n",
      "Epoch 04 | train_loss=0.7108 acc=0.7583 | val_loss=0.5284 acc=0.8564\n",
      "Epoch 05 | train_loss=0.4624 acc=0.8456 | val_loss=0.3005 acc=0.9152\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- Simulate pre-existing X and y tensors as requested ---\n",
    "    NUM_CLASSES = 12\n",
    "    NUM_IMAGES = 2712\n",
    "    IMAGE_HEIGHT = 144\n",
    "    IMAGE_WIDTH = 192\n",
    "\n",
    "    print(\"\\nSimulating pre-existing X and y tensors...\")\n",
    "\n",
    "\n",
    "    print(f\"Loaded X shape: {X.shape}\")\n",
    "    print(f\"Loaded y shape: {y.shape}\")\n",
    "\n",
    "    # --- Prepare the data for training ---\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_one_hot = tf.one_hot(y, NUM_CLASSES)\n",
    "    \n",
    "    # Shuffle and split the dataset\n",
    "    dataset_size = len(y)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    \n",
    "    full_dataset = tf.data.Dataset.from_tensor_slices((X, y_one_hot))\n",
    "    full_dataset = full_dataset.shuffle(buffer_size=dataset_size)\n",
    "    \n",
    "    ds_train = full_dataset.take(train_size).batch(8)\n",
    "    ds_val = full_dataset.skip(train_size).batch(8)\n",
    "    \n",
    "    # --- Train the model ---\n",
    "    print(\"\\nStarting CNN training...\")\n",
    "    model = SimpleCNN(num_classes=NUM_CLASSES)\n",
    "    train(model, ds_train, ds_val, epochs=5, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2213f80",
   "metadata": {},
   "source": [
    "### Test frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0107dce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 11, 0, 0, 0, 0, 0, 0]\n",
      "[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test = X[:8]\n",
    "res = [tf.argmax(model(test)[i]).numpy() for i in range(8)]\n",
    "print(res)\n",
    "# print((model(X[:8], training=False)))\n",
    "print(y[:8].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091099d",
   "metadata": {},
   "source": [
    "## CNN with Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb63a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 07:34:50.950703: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - ETA: 0s - loss: 1.1773 - accuracy: 0.6266\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57459, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 12s 40ms/step - loss: 1.1773 - accuracy: 0.6266 - val_loss: 1.2776 - val_accuracy: 0.5746\n",
      "Epoch 2/20\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.8645\n",
      "Epoch 2: val_accuracy improved from 0.57459 to 0.61326, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 37ms/step - loss: 0.4301 - accuracy: 0.8645 - val_loss: 1.1798 - val_accuracy: 0.6133\n",
      "Epoch 3/20\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9175\n",
      "Epoch 3: val_accuracy improved from 0.61326 to 0.76243, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 36ms/step - loss: 0.2745 - accuracy: 0.9175 - val_loss: 0.7536 - val_accuracy: 0.7624\n",
      "Epoch 4/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9571\n",
      "Epoch 4: val_accuracy improved from 0.76243 to 0.76611, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 37ms/step - loss: 0.1558 - accuracy: 0.9567 - val_loss: 0.7078 - val_accuracy: 0.7661\n",
      "Epoch 5/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9668\n",
      "Epoch 5: val_accuracy improved from 0.76611 to 0.78821, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 36ms/step - loss: 0.1269 - accuracy: 0.9663 - val_loss: 0.6732 - val_accuracy: 0.7882\n",
      "Epoch 6/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9659\n",
      "Epoch 6: val_accuracy improved from 0.78821 to 0.79742, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 37ms/step - loss: 0.1121 - accuracy: 0.9659 - val_loss: 0.6224 - val_accuracy: 0.7974\n",
      "Epoch 7/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9834\n",
      "Epoch 7: val_accuracy improved from 0.79742 to 0.92449, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 10s 38ms/step - loss: 0.0752 - accuracy: 0.9829 - val_loss: 0.2334 - val_accuracy: 0.9245\n",
      "Epoch 8/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0955 - accuracy: 0.9719\n",
      "Epoch 8: val_accuracy did not improve from 0.92449\n",
      "272/272 [==============================] - 11s 39ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.5415 - val_accuracy: 0.8177\n",
      "Epoch 9/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9811\n",
      "Epoch 9: val_accuracy did not improve from 0.92449\n",
      "272/272 [==============================] - 11s 41ms/step - loss: 0.0688 - accuracy: 0.9806 - val_loss: 0.2557 - val_accuracy: 0.9079\n",
      "Epoch 10/20\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9829\n",
      "Epoch 10: val_accuracy did not improve from 0.92449\n",
      "272/272 [==============================] - 11s 41ms/step - loss: 0.0665 - accuracy: 0.9829 - val_loss: 0.4816 - val_accuracy: 0.8913\n",
      "Epoch 11/20\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9811\n",
      "Epoch 11: val_accuracy did not improve from 0.92449\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.9023 - val_accuracy: 0.7422\n",
      "Epoch 12/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9834\n",
      "Epoch 12: val_accuracy improved from 0.92449 to 0.93370, saving model to cnn_best.h5\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.1940 - val_accuracy: 0.9337\n",
      "Epoch 13/20\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9848\n",
      "Epoch 13: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.0569 - accuracy: 0.9848 - val_loss: 0.4247 - val_accuracy: 0.8656\n",
      "Epoch 14/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9797\n",
      "Epoch 14: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.0706 - accuracy: 0.9793 - val_loss: 0.5253 - val_accuracy: 0.8343\n",
      "Epoch 15/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9880\n",
      "Epoch 15: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 0.1782 - val_accuracy: 0.9282\n",
      "Epoch 16/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9958\n",
      "Epoch 16: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 15s 57ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.5685 - val_accuracy: 0.8122\n",
      "Epoch 17/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9885\n",
      "Epoch 17: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 19s 70ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 1.5761 - val_accuracy: 0.7072\n",
      "Epoch 18/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9843\n",
      "Epoch 18: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 18s 67ms/step - loss: 0.0468 - accuracy: 0.9839 - val_loss: 0.4066 - val_accuracy: 0.8803\n",
      "Epoch 19/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9792\n",
      "Epoch 19: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 17s 64ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.4164 - val_accuracy: 0.9079\n",
      "Epoch 20/20\n",
      "271/272 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9760\n",
      "Epoch 20: val_accuracy did not improve from 0.93370\n",
      "272/272 [==============================] - 16s 60ms/step - loss: 0.0757 - accuracy: 0.9756 - val_loss: 0.4159 - val_accuracy: 0.8692\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Utils function\n",
    "# Save best model check point\n",
    "checkpoint_cb = ModelCheckpoint(\"cnn_best.h5\", \n",
    "                                save_best_only=True, \n",
    "                                monitor=\"val_accuracy\",    \n",
    "                                mode=\"max\",                \n",
    "                                save_weights_only=True,     \n",
    "                                verbose=1)\n",
    "\n",
    "# He initializer function\n",
    "def he_init(shape, dtype=None):\n",
    "    fan_in = tf.cast(tf.reduce_prod(shape[:-1]), tf.float32)\n",
    "    std = tf.sqrt(2.0 / fan_in)\n",
    "    return tf.random.normal(shape, stddev=std)\n",
    "\n",
    "NUM_CLASSES = 12 \n",
    "\n",
    "# Early stopping\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    patience=5, restore_best_weights=True,\n",
    "    monitor=\"val_loss\", mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "CNN = keras.Sequential([\n",
    "    # Block 1\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                  kernel_initializer=he_init, activation=None,\n",
    "                  input_shape=(144, 192, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Block 2\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "                  kernel_initializer=he_init, activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Block 3\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\",\n",
    "                  kernel_initializer=he_init, activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Dense head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, kernel_initializer=he_init, activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Output\n",
    "    layers.Dense(NUM_CLASSES, activation=\"softmax\", kernel_initializer=he_init),\n",
    "])\n",
    "\n",
    "# Split train/val\n",
    "X_np = X.numpy() if isinstance(X, tf.Tensor) else X\n",
    "y_np = y.numpy() if isinstance(y, tf.Tensor) else y\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_np, y_np, test_size=0.2, random_state=42, stratify=y_np\n",
    ")\n",
    "\n",
    "# Compile (match activation choice!)\n",
    "CNN.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # softmax used\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = CNN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d92daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 36ms/step - loss: 0.1940 - accuracy: 0.9337\n",
      "Best model -> val_acc=0.9337, val_loss=0.1940\n"
     ]
    }
   ],
   "source": [
    "# After training, load back the best weights:\n",
    "CNN.load_weights(\"cnn_best.h5\")\n",
    "\n",
    "# Now CNN is restored to the best epoch\n",
    "val_loss, val_acc = CNN.evaluate(X_val, y_val)\n",
    "print(f\"Best model -> val_acc={val_acc:.4f}, val_loss={val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76c15154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 144, 192, 3)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "[3 6 2 0 5 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "test = X_val[:8]\n",
    "print(test.shape)\n",
    "# res = [tf.argmax(CNN.predict(test[i])).numpy() for i in range(8)]\n",
    "res = CNN.predict(test)\n",
    "for i in range(8):\n",
    "    print(tf.argmax(res[i]).numpy())\n",
    "# print(res)\n",
    "# print((model(X[:8], training=False)))\n",
    "print(y_val[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a132e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodeHTTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
