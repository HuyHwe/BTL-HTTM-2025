{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72174e76",
   "metadata": {},
   "source": [
    "## Bước 1: Tạo X, y là bộ dữ liệu từ ảnh png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a0bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a dummy image at: test_image.png\n",
      "\n",
      "Successfully converted image to TensorFlow tensor!\n",
      "Tensor shape: (1, 100, 100, 3)\n",
      "Data type: <dtype: 'float32'>\n",
      "\n",
      "Cleaned up dummy file: test_image.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 19:13:50.711934: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-09-14 19:13:50.711949: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-14 19:13:50.711953: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-09-14 19:13:50.712149: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-14 19:13:50.712336: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2712, 144, 192, 3) (2712,)\n"
     ]
    }
   ],
   "source": [
    "# Merge all the code into a single script\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def parse_png_to_tensor(image_path: str) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Parses a PNG image file into a TensorFlow tensor.\n",
    "\n",
    "    This function is updated to be compatible with a TensorFlow training loop.\n",
    "    It converts the image to RGB format, normalizes the pixel values to a\n",
    "    0-1 range, and adds a batch dimension.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the PNG image.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A TensorFlow tensor of the image with a shape of\n",
    "                   (1, height, width, 3). Returns an empty tensor if the file\n",
    "                   cannot be processed.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File not found at {image_path}\")\n",
    "        return tf.empty(0)\n",
    "\n",
    "    try:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert the image to RGB format. This handles different modes like RGBA or P.\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert the PIL Image object to a NumPy array.\n",
    "        # The shape of the array will be (height, width, channels)\n",
    "        numpy_array = np.array(image, dtype=np.float32)\n",
    "        \n",
    "        # Normalize the pixel values from 0-255 to 0.0-1.0\n",
    "        normalized_array = numpy_array / 255.0\n",
    "        \n",
    "        # Convert the NumPy array to a TensorFlow tensor.\n",
    "        # The tensor will have a shape of (height, width, channels)\n",
    "        image_tensor = tf.convert_to_tensor(normalized_array)\n",
    "        \n",
    "        # Add a batch dimension at the beginning to match the expected\n",
    "        # input shape for a model (batch_size, height, width, channels)\n",
    "        final_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "        return final_tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the image: {e}\")\n",
    "        return tf.empty(0)\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a dummy PNG file for testing\n",
    "    dummy_image_path = \"test_image.png\"\n",
    "    \n",
    "    # Create a 100x100 white image with RGB channels\n",
    "    dummy_image = Image.new('RGB', (100, 100), 'white')\n",
    "    dummy_image.save(dummy_image_path)\n",
    "    print(f\"Created a dummy image at: {dummy_image_path}\")\n",
    "\n",
    "    # Call the parse function on the dummy image\n",
    "    image_tensor = parse_png_to_tensor(dummy_image_path)\n",
    "\n",
    "    # Check the result\n",
    "    if image_tensor.shape.num_elements() > 0:\n",
    "        print(\"\\nSuccessfully converted image to TensorFlow tensor!\")\n",
    "        print(f\"Tensor shape: {image_tensor.shape}\")\n",
    "        print(f\"Data type: {image_tensor.dtype}\")\n",
    "    else:\n",
    "        print(\"\\nFailed to convert image to tensor.\")\n",
    "\n",
    "    # Clean up the dummy file\n",
    "    os.remove(dummy_image_path)\n",
    "    print(f\"\\nCleaned up dummy file: {dummy_image_path}\")\n",
    "\n",
    "\n",
    "IMG_SIZE = [144, 192]\n",
    "labels = [l for l in os.listdir(\"./dataset\") if l != \".DS_Store\"]\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "for i, label in enumerate(labels):\n",
    "    img_list = os.listdir(f\"./dataset/{label}/\")\n",
    "    for img in img_list:\n",
    "        img_path = f\"./dataset/{label}/{img}\"\n",
    "        tensor = parse_png_to_tensor(img_path)\n",
    "        # Resize and check for valid tensor\n",
    "        if tensor.shape.num_elements() > 0:\n",
    "            resized = tf.image.resize(tf.squeeze(tensor, axis=0), IMG_SIZE)\n",
    "            X_list.append(resized)\n",
    "            y_list.append(i)\n",
    "\n",
    "X = tf.stack(X_list, axis=0)\n",
    "y = tf.convert_to_tensor(y_list, dtype=tf.int32)\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d7034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2712, 144, 192, 3]), TensorShape([2712]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e13c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = [144,192]\n",
    "NUM_CLASSES = 12\n",
    "BATCH = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# def parse_example(path, label):\n",
    "#     img = tf.io.read_file(path)\n",
    "#     img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "#     img = tf.image.resize(img, [IMG_SIZE[0], IMG_SIZE[1]], antialias=True)\n",
    "#     img = tf.cast(img, tf.float32) / 255.0\n",
    "#     return img, tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "# def augment(img, label):\n",
    "#     img = tf.image.random_flip_left_right(img)\n",
    "#     img = tf.image.random_brightness(img, max_delta=0.08)\n",
    "#     img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "#     img = tf.image.random_saturation(img, 0.9, 1.1)\n",
    "#     return img, label\n",
    "\n",
    "# def make_ds(paths, labels, training=True):\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "#     ds = ds.shuffle(2048) if training else ds\n",
    "#     ds = ds.map(parse_example, num_parallel_calls=AUTOTUNE)\n",
    "#     ds = ds.map(augment, num_parallel_calls=AUTOTUNE) if training else ds\n",
    "#     return ds.batch(BATCH).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c53a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_init(shape):\n",
    "    fan_in = tf.cast(tf.math.reduce_prod(shape[:-1]), tf.float32)\n",
    "    std = tf.sqrt(2.0/fan_in)\n",
    "    return tf.random.normal(shape, stddev=std)\n",
    "\n",
    "class SimpleCNN:\n",
    "    def __init__(self, num_classes=12):\n",
    "        self.W1 = tf.Variable(he_init([3,3,3,32]));  self.b1 = tf.Variable(tf.zeros([32]))\n",
    "        self.W2 = tf.Variable(he_init([3,3,32,64])); self.b2 = tf.Variable(tf.zeros([64]))\n",
    "        self.W3 = tf.Variable(he_init([3,3,64,128]));self.b3 = tf.Variable(tf.zeros([128]))\n",
    "        \n",
    "        # We will initialize the weights for the dense layers dynamically\n",
    "        # based on the input image shape.\n",
    "        self.W4 = None\n",
    "        self.b4 = None\n",
    "        self.W5 = tf.Variable(he_init([256, num_classes]))\n",
    "        self.b5 = tf.Variable(tf.zeros([num_classes]))\n",
    "        self.weights_initialized = False\n",
    "\n",
    "    def __call__(self, x, training=False, drop_rate=0.3):\n",
    "        # x: [B, H, W, 3]\n",
    "        x = tf.nn.conv2d(x, self.W1, strides=1, padding='SAME') + self.b1\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        x = tf.nn.conv2d(x, self.W2, strides=1, padding='SAME') + self.b2\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        x = tf.nn.conv2d(x, self.W3, strides=1, padding='SAME') + self.b3\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
    "\n",
    "        if not self.weights_initialized:\n",
    "            # Dynamically calculate the flattened dimension and initialize weights\n",
    "            # This is done the first time the model is called with a new input shape\n",
    "            flat_dim = tf.math.reduce_prod(x.shape[1:])\n",
    "            self.W4 = tf.Variable(he_init([flat_dim, 256]))\n",
    "            self.b4 = tf.Variable(tf.zeros([256]))\n",
    "            self.weights_initialized = True\n",
    "\n",
    "        x = tf.reshape(x, [-1, tf.math.reduce_prod(x.shape[1:])])\n",
    "        x = tf.matmul(x, self.W4) + self.b4\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        if training and drop_rate > 0:\n",
    "            keep = 1.0 - drop_rate\n",
    "            mask = tf.cast(tf.random.uniform(tf.shape(x)) < keep, x.dtype)\n",
    "            x = (x * mask) / keep\n",
    "\n",
    "        logits = tf.matmul(x, self.W5) + self.b5\n",
    "        return logits\n",
    "\n",
    "    @property\n",
    "    def variables(self):\n",
    "        # Make sure to return all variables, including the dynamically created ones\n",
    "        return [self.W1,self.b1,self.W2,self.b2,self.W3,self.b3,self.W4,self.b4,self.W5,self.b5]\n",
    "\n",
    "import math\n",
    "\n",
    "def cross_entropy_loss(logits, onehot_labels):\n",
    "    per_ex = tf.nn.softmax_cross_entropy_with_logits(labels=onehot_labels, logits=logits)\n",
    "    return tf.reduce_mean(per_ex)\n",
    "\n",
    "def accuracy(logits, onehot_labels):\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    true = tf.argmax(onehot_labels, axis=1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=1e-3, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}\n",
    "\n",
    "    def apply_gradients(self, grads, vars):\n",
    "        for g, v in zip(grads, vars):\n",
    "            if g is None:\n",
    "                continue\n",
    "            key = id(v)\n",
    "            if key not in self.v:\n",
    "                self.v[key] = tf.zeros_like(v)\n",
    "            self.v[key] = self.momentum*self.v[key] + g\n",
    "            v.assign_sub(self.lr * self.v[key])\n",
    "\n",
    "def train(model, ds_train, ds_val, epochs=15, lr=1e-3):\n",
    "    opt = SGD(lr=lr, momentum=0.9)\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss = tf.metrics.Mean(); tr_acc = tf.metrics.Mean()\n",
    "        for x,y in ds_train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x, training=True)\n",
    "                loss = cross_entropy_loss(logits, y)\n",
    "            grads = tape.gradient(loss, model.variables)\n",
    "            opt.apply_gradients(grads, model.variables)\n",
    "\n",
    "            tr_loss.update_state(loss)\n",
    "            tr_acc.update_state(accuracy(logits, y))\n",
    "\n",
    "        va_loss = tf.metrics.Mean(); va_acc = tf.metrics.Mean()\n",
    "        for x,y in ds_val:\n",
    "            logits = model(x, training=False)\n",
    "            va_loss.update_state(cross_entropy_loss(logits, y))\n",
    "            va_acc.update_state(accuracy(logits, y))\n",
    "\n",
    "        print(f\"Epoch {ep:02d} | train_loss={tr_loss.result():.4f} acc={tr_acc.result():.4f} \"\n",
    "              f\"| val_loss={va_loss.result():.4f} acc={va_acc.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8263ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating pre-existing X and y tensors...\n",
      "Loaded X shape: (2712, 144, 192, 3)\n",
      "Loaded y shape: (2712,)\n",
      "\n",
      "Starting CNN training...\n",
      "Epoch 01 | train_loss=2.2437 acc=0.2440 | val_loss=1.7477 acc=0.4546\n",
      "Epoch 02 | train_loss=1.4871 acc=0.4899 | val_loss=1.4336 acc=0.5538\n",
      "Epoch 03 | train_loss=1.0085 acc=0.6613 | val_loss=1.3086 acc=0.5502\n",
      "Epoch 04 | train_loss=0.6508 acc=0.7840 | val_loss=0.4897 acc=0.8372\n",
      "Epoch 05 | train_loss=0.4734 acc=0.8424 | val_loss=0.2917 acc=0.9076\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- Simulate pre-existing X and y tensors as requested ---\n",
    "    NUM_CLASSES = 12\n",
    "    NUM_IMAGES = 2712\n",
    "    IMAGE_HEIGHT = 144\n",
    "    IMAGE_WIDTH = 192\n",
    "\n",
    "    print(\"\\nSimulating pre-existing X and y tensors...\")\n",
    "\n",
    "\n",
    "    print(f\"Loaded X shape: {X.shape}\")\n",
    "    print(f\"Loaded y shape: {y.shape}\")\n",
    "\n",
    "    # --- Prepare the data for training ---\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_one_hot = tf.one_hot(y, NUM_CLASSES)\n",
    "    \n",
    "    # Shuffle and split the dataset\n",
    "    dataset_size = len(y)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    \n",
    "    full_dataset = tf.data.Dataset.from_tensor_slices((X, y_one_hot))\n",
    "    full_dataset = full_dataset.shuffle(buffer_size=dataset_size)\n",
    "    \n",
    "    ds_train = full_dataset.take(train_size).batch(8)\n",
    "    ds_val = full_dataset.skip(train_size).batch(8)\n",
    "    \n",
    "    # --- Train the model ---\n",
    "    print(\"\\nStarting CNN training...\")\n",
    "    model = SimpleCNN(num_classes=NUM_CLASSES)\n",
    "    train(model, ds_train, ds_val, epochs=5, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107dce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodeHTTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
